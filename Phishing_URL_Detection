# -*- coding: utf-8 -*-
"""Phishing_URL_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z2WbgKGRaG1kpqvMSCmUgBMl3f2wK79f

PROGETTO IA 2
1. Import librerie
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

""" Caricamento dataset"""

from google.colab import files
files.upload()

df = pd.read_csv("PhiUSIIL_Phishing_URL_Dataset.csv")

"""2. EDA: Informazioni statistiche e descrittive,
Distribuzione classi,
Correlazioni
"""

#informazioni statistiche e descrittive
print(df.info())
print(df.describe())
print(df['label'].value_counts())

#Distribuzione classi
sns.countplot(x='label', data=df)
plt.show()

# Istogramma della lunghezza dell'URL
plt.figure()
plt.hist(df['URLLength'], bins=50)
plt.xlabel('Lunghezza URL')
plt.ylabel('Frequenza')
plt.title('Distribuzione della lunghezza degli URL')
plt.show()

# Istogramma del numero di elementi esterni nella pagina web
plt.figure()
plt.hist(df['NoOfExternalRef'], bins=50)
plt.xlabel('Numero di elementi esterni')
plt.ylabel('Frequenza')
plt.title('Distribuzione del numero di elementi esterni nella pagina web')
plt.show()

#boxplot
features = ['URLLength', 'NoOfDegitsInURL', 'NoOfOtherSpecialCharsInURL', 'SpacialCharRatioInURL']

for feat in features:
    plt.figure(figsize=(6,4))
    sns.boxplot(x='label', y=feat, data=df)
    plt.title(f"Boxplot of {feat} by class")
    plt.xlabel("Class (0 = Legit, 1 = Phishing)")
    plt.ylabel(feat)
    plt.show()
#scarletplot
plt.figure(figsize=(7,5))
sns.scatterplot(
    x='URLLength',
    y='SpacialCharRatioInURL',
    hue='label',
    data=df,
    alpha=0.5
)
plt.title("Scatterplot: URL Length vs Special Character Ratio")
plt.xlabel("URL Length")
plt.ylabel("Special Character Ratio")
plt.legend(title="Class (0=Legit, 1=Phishing)")
plt.show()

#Correlazioni
plt.figure(figsize=(12,8))
numeric_df = df.select_dtypes(include=np.number)
sns.heatmap(numeric_df.corr(), cmap='coolwarm')
plt.show()

"""3. PREPROCESSING E FEATURE ENGINEERING"""

# Valori mancanti
print("VALORI MANCANTI:")
print(df.isnull().sum())
rows_before = len(df)
df_cleaned = df.dropna(subset=['label'])
rows_after = len(df_cleaned)
print(f"Righe eliminate: {rows_before - rows_after}")

# FEATURE ENGINEERING: Estrai nuove feature dalle URL
import re
def url_features(url):
    return {
        'url_length': len(url),
        'num_digits': sum(c.isdigit() for c in url),
        'num_special': len(re.findall(r'[^a-zA-Z0-9]', url)),
        'has_https': int('https' in url),
        'num_dots': url.count('.'),
        'num_slashes': url.count('/'),
        'entropy': -sum(p*np.log2(p) for p in pd.Series(list(url)).value_counts(normalize=True))
    }
#Aggiunta feature al dataset
url_feats = df['URL'].apply(url_features).apply(pd.Series)
df_cleaned = pd.concat([df, url_feats], axis=1)

print("Nuove feature create dall'URL:")
print(url_feats.head())
print("\nStatistiche:")
print(url_feats.describe())

# Gestione Valori Categoriali
print(" CATEGORIALI:")
categorical_cols = ['URL', 'FILENAME', 'Domain', 'TLD', 'Title']
print("Cardinalita:")
for col in categorical_cols:
    if col in df_cleaned.columns:
        print(f"  {col}: {df_cleaned[col].nunique()} valori unici")
print("Strategia: eliminazione + feature extraction dall'URL")

# Prepara feature X e target y (eliminazione variabili testuali)
df_cleaned = df.dropna(subset=['label'])

X = df_cleaned.drop(columns=['label', 'URL', 'FILENAME', 'Domain', 'TLD', 'Title'])
y = df_cleaned['label']

print("Dataset finale")
print(f"\nShape: X={X.shape}, y={y.shape}")

# Divisione dati in train (80%) e test (20%) stratificato
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
print("TRAIN-TEST SPLIT:")
print(f"Train: {X_train.shape}")
print(f"Test: {X_test.shape}")
print(f"Distribuzione train:\n{y_train.value_counts(normalize=True)}")

# Normalizzazione dati per Logistic e KNN
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
print("StandardScaler applicato")
print(f"Train scaled: {X_train.shape}")
print(f"Test scaled: {X_test.shape}")

"""4. MODELLI DI MACHINE LEARNING

4.1 Logistic regression
"""

from sklearn.linear_model import LogisticRegression
lr= LogisticRegression(max_iter=1000, random_state=42)
lr.fit(X_train, y_train)
print(" Regressione Logistica addestrata")

"""4.2 Naive Bayes"""

from sklearn.naive_bayes import GaussianNB

nb = GaussianNB()
nb.fit(X_train, y_train)
print(" Naive Bayes addestrato")

"""4.3 KNN"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
print("KNN (k=5) addestrato")

"""5. CROSS VALIDATION"""

from sklearn.model_selection import cross_val_score
#dizionario dei modelli
models = {
    "Logistic Regression": lr,
    "Naive Bayes": nb,
    "KNN": knn
}
for name, model in models.items():
    scores = cross_val_score(model, X, y, cv=5, scoring='f1')
    print(f"{name}: mean F1={scores.mean():.4f}, std={scores.std():.4f}")

"""6. VALUTAZIONE ED ANALISI DEI RISULTATI

6.1 Predizioni sul test set
"""

#dizionario dei modelli
models = {
    "Logistic Regression": lr,
    "Naive Bayes": nb,
    "KNN": knn
}

# Predizioni
predictions = {}
for name, model in models.items():
    predictions[name] = {
        'y_pred': model.predict(X_test),
        'y_prob': model.predict_proba(X_test)[:, 1]
    }

# VISUALIZZA UN PEZZO DELLE PREVISIONI

# Converti y_test in array per facilità
y_test_array = y_test.values

# Mostra prime 3 previsioni
for i in range(3):
    reale = y_test_array[i]
    reale_label = " Phishing" if reale == 1 else "Legittimo"

    print(f"\n Esempio {i+1}: REALE = {reale_label}")

    # Previsioni di ogni modello
    for name in predictions.keys():
        pred_class = predictions[name]['y_pred'][i]
        pred_prob = predictions[name]['y_prob'][i]

        # Label predetta
        pred_label = "Phishing" if pred_class == 1 else "Legittimo"

        # Check se corretto
        if pred_class == reale:
            status = "CORRETTO"
        else:
            status = "SBAGLIATO"

        # Stampa con probabilità
        print(f"   {name:20s} → {pred_label:10s} | Probabilità: {pred_prob:6.2%} | {status}")

"""6.2  Valutazione dei modelli"""

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import seaborn as sns
import matplotlib.pyplot as plt

# Extract predictions for each model
y_pred_lr = predictions["Logistic Regression"]['y_pred']
y_prob_lr = predictions["Logistic Regression"]['y_prob']

y_pred_nb = predictions["Naive Bayes"]['y_pred']
y_prob_nb = predictions["Naive Bayes"]['y_prob']

y_pred_knn = predictions["KNN"]['y_pred']
y_prob_knn = predictions["KNN"]['y_prob']

# LOGISTIC REGRESSION
print("=== LOGISTIC REGRESSION ===")
print(classification_report(y_test, y_pred_lr))

cm_lr = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm_lr, annot=True, fmt='d')
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

auc_lr = roc_auc_score(y_test, y_prob_lr)
print("AUC Logistic Regression:", auc_lr)

# NAIVE BAYES
print("=== NAIVE BAYES ===")
print(classification_report(y_test, y_pred_nb))

cm_nb = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(cm_nb, annot=True, fmt='d')
plt.title("Confusion Matrix - Naive Bayes")
plt.show()

auc_nb = roc_auc_score(y_test, y_prob_nb)
print("AUC Naive Bayes:", auc_nb)

# KNN
print("=== KNN ===")
print(classification_report(y_test, y_pred_knn))

cm_knn = confusion_matrix(y_test, y_pred_knn)
sns.heatmap(cm_knn, annot=True, fmt='d')
plt.title("Confusion Matrix - KNN")
plt.show()

auc_knn = roc_auc_score(y_test, y_prob_knn)
print("AUC KNN:", auc_knn)

"""6.3 TABELLA RISULTATI"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import precision_score, recall_score

results = []

for name, model in models.items():
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:,1]

    results.append({
        "Model": name,
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1": f1_score(y_test, y_pred),
        "AUC": roc_auc_score(y_test, y_prob)
    })

results_df = pd.DataFrame(results)
results_df

"""6.4 CURVA ROC"""

from sklearn.metrics import roc_curve

plt.figure()

for name, model in models.items():
    y_prob = model.predict_proba(X_test)[:,1]
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    plt.plot(fpr, tpr, label=name)

plt.plot([0,1],[0,1],'--')
plt.legend()
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves Comparison")
plt.show()
